1
00:00:00,000 --> 00:00:01,545
Welcome to Edinburgh.

2
00:00:01,545 --> 00:00:05,745
I'm one of the lecturers on
the Informatics 1A course.

3
00:00:05,745 --> 00:00:09,090
This may be the first video
you've seen for this course.

4
00:00:09,090 --> 00:00:10,785
So let's start with the beginning.

5
00:00:10,785 --> 00:00:12,345
I'm Michael Fourman,

6
00:00:12,345 --> 00:00:14,669
Philip Wadler's
the other Lecturer.

7
00:00:14,669 --> 00:00:16,470
I'll be with you for

8
00:00:16,470 --> 00:00:19,215
the computation and logic
part of the course.

9
00:00:19,215 --> 00:00:22,170
And Philip will be
teaching the Haskell.

10
00:00:22,170 --> 00:00:25,820
But occasionally, I will be --
more than occasionally,

11
00:00:25,820 --> 00:00:28,550
quite often, I will
be using Haskell

12
00:00:28,550 --> 00:00:29,840
and you will be using Haskell

13
00:00:29,840 --> 00:00:31,505
in the logic part of the course.

14
00:00:31,505 --> 00:00:34,970
And sometimes Philip
will be talking

15
00:00:34,970 --> 00:00:39,470
about logic as a tool for
reasoning about programs.

16
00:00:39,470 --> 00:00:41,540
So both things will happen.

17
00:00:41,540 --> 00:00:43,610
What I want to do today is not

18
00:00:43,610 --> 00:00:45,650
do any of the technical stuff,

19
00:00:45,650 --> 00:00:49,250
but to cover a part of
the wider context, 

20
00:00:49,250 --> 00:00:50,420
things you should bear in

21
00:00:50,420 --> 00:00:53,255
mind throughout your
time at Edinburgh.

22
00:00:53,255 --> 00:00:59,510
And the first one is
that informatics is not

23
00:00:59,510 --> 00:01:01,475
just a bit of

24
00:01:01,475 --> 00:01:06,285
theory that you can do that's
separate from the world.

25
00:01:06,285 --> 00:01:09,070
It's become very apparent that

26
00:01:09,070 --> 00:01:11,590
things like the
Internet are changing

27
00:01:11,590 --> 00:01:14,575
the way society
works, are changing

28
00:01:14,575 --> 00:01:17,065
the way democracy works,

29
00:01:17,065 --> 00:01:19,105
are changing the
way commerce works.

30
00:01:19,105 --> 00:01:22,420
So whenever you are
doing your informatics,

31
00:01:22,420 --> 00:01:24,880
you will also need to be
thinking about what are

32
00:01:24,880 --> 00:01:27,340
the possible effects of

33
00:01:27,340 --> 00:01:30,595
the things you're
doing and the ethical,

34
00:01:30,595 --> 00:01:32,950
legal, economic,

35
00:01:32,950 --> 00:01:34,000
organisational,

36
00:01:34,000 --> 00:01:37,405
and social issues that
affect what you do.

37
00:01:37,405 --> 00:01:39,610
You need to bear in mind that

38
00:01:39,610 --> 00:01:42,655
technology can be
used and misused.

39
00:01:42,655 --> 00:01:46,060
So I'll just raise that
to plant the idea in

40
00:01:46,060 --> 00:01:49,970
your heads and you should
think of that often,

41
00:01:49,970 --> 00:01:52,010
but don't let it
distract you too much

42
00:01:52,010 --> 00:01:54,080
from also thinking about getting

43
00:01:54,080 --> 00:01:56,420
on with understanding, and the theory,

44
00:01:56,420 --> 00:01:59,375
and having the fun
of the practice.

45
00:01:59,375 --> 00:02:02,280
Those things can happen as well.

46
00:02:02,890 --> 00:02:07,835
There is an immediate issue
that I also want to raise,

47
00:02:07,835 --> 00:02:12,260
which is really
illustrated by this slide.

48
00:02:12,260 --> 00:02:13,910
And you can find
plenty of slides like

49
00:02:13,910 --> 00:02:16,130
this or more
up-to-date news about

50
00:02:16,130 --> 00:02:21,710
the same things. In the
workplace in general,

51
00:02:21,710 --> 00:02:24,425
but in IT, in particular,

52
00:02:24,425 --> 00:02:27,005
there is a gender pay gap.

53
00:02:27,005 --> 00:02:31,310
If you look in IT, there's
also a participation

54
00:02:31,310 --> 00:02:33,875
gap based on gender.

55
00:02:33,875 --> 00:02:38,810
Certainly in Europe and
the UK and the USA,

56
00:02:38,810 --> 00:02:41,674
the number of women
in the subject

57
00:02:41,674 --> 00:02:44,720
is much smaller than
it should be: it's not

58
00:02:44,720 --> 00:02:46,550
because women are not capable,

59
00:02:46,550 --> 00:02:50,240
it's because societal
issues stop them or

60
00:02:50,240 --> 00:02:55,130
discourage them from
participating in this area.

61
00:02:55,130 --> 00:02:57,560
Now, we're lucky there are plenty

62
00:02:57,560 --> 00:03:00,440
of women in informatics

63
00:03:00,440 --> 00:03:02,180
at Edinburgh, but we are not as

64
00:03:02,180 --> 00:03:04,685
lucky as we might be because
there aren't enough.

65
00:03:04,685 --> 00:03:07,730
Just as with almost
every other university

66
00:03:07,730 --> 00:03:09,810
in the western world.

67
00:03:09,820 --> 00:03:14,570
What we want to do is to
make sure that your time

68
00:03:14,570 --> 00:03:19,460
here is not contributing
to those problems.

69
00:03:19,460 --> 00:03:22,490
If you look at the big companies,

70
00:03:22,490 --> 00:03:24,470
many of them have programs

71
00:03:24,470 --> 00:03:26,735
designed to attract more women.

72
00:03:26,735 --> 00:03:30,365
But generally, it's
been identified that

73
00:03:30,365 --> 00:03:32,840
one of the reasons
women don't like

74
00:03:32,840 --> 00:03:35,390
to participate is because

75
00:03:35,390 --> 00:03:40,565
of the normally unconscious
attitudes of their peers,

76
00:03:40,565 --> 00:03:44,255
of the people who
are in the industry.

77
00:03:44,255 --> 00:03:47,930
So what we want to
make sure of is that

78
00:03:47,930 --> 00:03:52,115
those forces aren't dissuading

79
00:03:52,115 --> 00:03:55,639
our students from continue
with that degree,

80
00:03:55,639 --> 00:03:57,920
continue with careers
after the degrees,

81
00:03:57,920 --> 00:04:00,695
or even coming here
in the first place.

82
00:04:00,695 --> 00:04:02,270
So right from the beginning,

83
00:04:02,270 --> 00:04:03,830
we want you to be aware

84
00:04:03,830 --> 00:04:06,350
of the ways you
interact with each

85
00:04:06,350 --> 00:04:09,560
other and try taking

86
00:04:09,560 --> 00:04:12,560
this Harvard Test
for implicit bias:

87
00:04:12,560 --> 00:04:18,125
you will find that you
get surprising results.

88
00:04:18,125 --> 00:04:21,605
I know of no one who's taken
this and thought about it,

89
00:04:21,605 --> 00:04:24,380
who hasn't been surprised at

90
00:04:24,380 --> 00:04:29,015
their own biases being

91
00:04:29,015 --> 00:04:33,305
more than they would have
expected if you just ask them.

92
00:04:33,305 --> 00:04:36,710
So we want to ensure our
graduates learn to change,

93
00:04:36,710 --> 00:04:39,020
try reading that...

94
00:04:39,020 --> 00:04:40,624
try watching that video,

95
00:04:40,624 --> 00:04:44,810
and think about these
things. You will be,

96
00:04:44,810 --> 00:04:48,080
and I'll talk about this
more later in this lecture,

97
00:04:48,080 --> 00:04:51,005
we'll be interacting
with each other.

98
00:04:51,005 --> 00:04:53,120
When you interact
with each other,

99
00:04:53,120 --> 00:04:56,420
be aware of the fact
that we are all

100
00:04:56,420 --> 00:04:59,750
subject to implicit biases,

101
00:04:59,750 --> 00:05:03,020
and try to make sure that

102
00:05:03,020 --> 00:05:07,655
those don't affect the ways
you interact with each other.

103
00:05:07,655 --> 00:05:10,970
If you experience problems,

104
00:05:10,970 --> 00:05:12,170
by all means bring it to

105
00:05:12,170 --> 00:05:14,390
our attention because we'd
like to address these things.

106
00:05:14,390 --> 00:05:15,920
But much the best
way of dealing with

107
00:05:15,920 --> 00:05:18,290
this is for everyone
on the course to

108
00:05:18,290 --> 00:05:20,480
understand the issues and talk

109
00:05:20,480 --> 00:05:23,645
about them openly
and address them.

110
00:05:23,645 --> 00:05:26,525
So in your interactions,

111
00:05:26,525 --> 00:05:29,210
and your interactions
will largely be online,

112
00:05:29,210 --> 00:05:30,590
which is even more difficult,

113
00:05:30,590 --> 00:05:33,515
I think, than face-to-face,

114
00:05:33,515 --> 00:05:35,900
don't be exclusive.

115
00:05:35,900 --> 00:05:38,240
One of the benefits of being at

116
00:05:38,240 --> 00:05:41,510
the university or being
in this cohort of

117
00:05:41,510 --> 00:05:42,680
people who were studying at

118
00:05:42,680 --> 00:05:45,410
Edinburgh is that
you get exposed to

119
00:05:45,410 --> 00:05:47,420
a wide variety of people from

120
00:05:47,420 --> 00:05:51,350
a wide variety of backgrounds,
who are all very smart.

121
00:05:51,350 --> 00:05:53,480
And the more you can

122
00:05:53,480 --> 00:05:55,550
benefit from being exposed

123
00:05:55,550 --> 00:05:57,305
to people who are not like you,

124
00:05:57,305 --> 00:06:01,085
the more, the more good you'll
get out of the experience.

125
00:06:01,085 --> 00:06:02,930
So don't be exclusive.

126
00:06:02,930 --> 00:06:05,240
Mix with people who
are not like you.

127
00:06:05,240 --> 00:06:08,120
Make sure that you're
not implicitly or

128
00:06:08,120 --> 00:06:11,150
subconsciously viewing them in

129
00:06:11,150 --> 00:06:13,640
a way that the facts
don't merit,

130
00:06:13,640 --> 00:06:16,040
they're all smart, they wouldn't
be here if they weren't,

131
00:06:16,040 --> 00:06:21,950
just as you wouldn't.
Develop for yourselves,

132
00:06:21,950 --> 00:06:23,960
a core value system.

133
00:06:23,960 --> 00:06:25,580
We need to treat each other

134
00:06:25,580 --> 00:06:28,175
fairly and respect each other.

135
00:06:28,175 --> 00:06:33,440
And change the way
you look at things.

136
00:06:33,440 --> 00:06:35,540
When you are interacting
with other people,

137
00:06:35,540 --> 00:06:39,275
try and be aware of
the possibility of,

138
00:06:39,275 --> 00:06:43,190
in fact, the prevalence
of implicit bias.

139
00:06:43,190 --> 00:06:46,820
Don't be the person who
excludes others in the group.

140
00:06:46,820 --> 00:06:50,225
Recognize your
unconscious actions.

141
00:06:50,225 --> 00:06:54,965
And if you are feeling
you're excluded,

142
00:06:54,965 --> 00:06:56,465
don't let that happen.

143
00:06:56,465 --> 00:07:01,050
Don't let them hold
you or others back.

144
00:07:02,170 --> 00:07:04,790
One of the skills
you'll learn from

145
00:07:04,790 --> 00:07:07,535
this course is to talk.

146
00:07:07,535 --> 00:07:09,260
You might think you
can talk very well

147
00:07:09,260 --> 00:07:11,135
already and I'm sure you can.

148
00:07:11,135 --> 00:07:20,255
But to talk concisely and precisely
about technical things.

149
00:07:20,255 --> 00:07:23,045
You need to learn these skills

150
00:07:23,045 --> 00:07:25,550
because often when
we're talking about

151
00:07:25,550 --> 00:07:28,190
programs or designs or systems,

152
00:07:28,190 --> 00:07:30,860
we need to make quite
subtle distinctions.

153
00:07:30,860 --> 00:07:32,510
And natural language
is often very

154
00:07:32,510 --> 00:07:35,105
bad at making those distinctions.

155
00:07:35,105 --> 00:07:36,920
So you will learn about

156
00:07:36,920 --> 00:07:40,730
formal languages a bit in this
course and more later on.

157
00:07:40,730 --> 00:07:45,350
But you will also learn to
use your natural languages,

158
00:07:45,350 --> 00:07:47,075
more precisely.

159
00:07:47,075 --> 00:07:50,660
And one of the ways you
will do that is by working

160
00:07:50,660 --> 00:07:54,995
with other people and
exercising those skills,

161
00:07:54,995 --> 00:08:00,120
talking to each other
about what goes on.

162
00:08:00,700 --> 00:08:03,080
So you should do that as much as

163
00:08:03,080 --> 00:08:05,855
possible. When you
have a problem,

164
00:08:05,855 --> 00:08:10,160
Don't think you're thick.

165
00:08:10,160 --> 00:08:13,085
Don't think, oh gosh,

166
00:08:13,085 --> 00:08:15,890
I can't do this. Think...

167
00:08:15,890 --> 00:08:17,840
who can I talk to about this

168
00:08:17,840 --> 00:08:19,970
so we can work it out together?

169
00:08:19,970 --> 00:08:21,710
And you will normally

170
00:08:21,710 --> 00:08:24,545
find that there are
plenty of people around.

171
00:08:24,545 --> 00:08:26,495
And talking together helps

172
00:08:26,495 --> 00:08:28,805
both of you to learn something.

173
00:08:28,805 --> 00:08:32,060
So do that as much as

174
00:08:32,060 --> 00:08:35,045
possible or almost
as much as possible.

175
00:08:35,045 --> 00:08:37,280
The one exception is there's

176
00:08:37,280 --> 00:08:39,200
some assessed work
in this course.

177
00:08:39,200 --> 00:08:41,330
And when you submit
assessed work,

178
00:08:41,330 --> 00:08:44,795
it should reflect your abilities.

179
00:08:44,795 --> 00:08:47,420
And basically, it should be

180
00:08:47,420 --> 00:08:50,570
your work. In preparing
to do the assessed work,

181
00:08:50,570 --> 00:08:53,465
of course, you should
talk with each other.

182
00:08:53,465 --> 00:08:56,540
But when it comes down to
what you're going to submit,

183
00:08:56,540 --> 00:09:01,260
you should make sure it's your
work and submit that.

184
00:09:02,590 --> 00:09:07,010
So... Informatics, we use
this word informatics.

185
00:09:07,010 --> 00:09:09,770
Why? Why not just
computer science or

186
00:09:09,770 --> 00:09:12,950
AI or computer engineering?

187
00:09:12,950 --> 00:09:16,190
And the answer is
because informatics is

188
00:09:16,190 --> 00:09:19,970
in some ways broader
than any one of those.

189
00:09:19,970 --> 00:09:26,060
It turns out that when
you're studying hardware,

190
00:09:26,060 --> 00:09:28,670
when you're studying
hot software,

191
00:09:28,670 --> 00:09:31,430
when you're studying 
human-computer


192
00:09:31,430 --> 00:09:33,260
human-computer interaction,

193
00:09:33,260 --> 00:09:36,560
when you're studying
artificial intelligence,

194
00:09:36,560 --> 00:09:40,175
in all those different
aspects of the study,

195
00:09:40,175 --> 00:09:43,130
you're thinking about information 
and

196
00:09:43,130 --> 00:09:45,755
the ways in which it is sensed,

197
00:09:45,755 --> 00:09:50,810
stored, processed,
communicated, and so on.

198
00:09:50,810 --> 00:09:54,380
So when we say Informatics,

199
00:09:54,380 --> 00:09:55,925
we try and be very broad.

200
00:09:55,925 --> 00:09:57,395
We're interested in the way

201
00:09:57,395 --> 00:10:00,875
the brain works as a computer.

202
00:10:00,875 --> 00:10:03,890
We're interested in
the way societies

203
00:10:03,890 --> 00:10:06,890
communicate with societies --
and ants communicate,

204
00:10:06,890 --> 00:10:08,945
we'd have people working
on those kinds of things.

205
00:10:08,945 --> 00:10:11,300
We're interested in information.

206
00:10:11,300 --> 00:10:14,435
And it turns out that
the basic mathematics

207
00:10:14,435 --> 00:10:18,980
and theory is a,

208
00:10:18,980 --> 00:10:23,010
is a foundation across
all of those subjects.

209
00:10:23,460 --> 00:10:26,755
So we talk about software,

210
00:10:26,755 --> 00:10:28,780
hardware, people and things,

211
00:10:28,780 --> 00:10:31,885
and they all sense,

212
00:10:31,885 --> 00:10:36,650
store, process, and
communicate information.

213
00:10:36,900 --> 00:10:42,220
Now, if you look in
our course handbook

214
00:10:42,220 --> 00:10:43,690
for the later years,

215
00:10:43,690 --> 00:10:45,940
you'll see that there
are many, many subjects,

216
00:10:45,940 --> 00:10:49,540
many many courses: block chains,

217
00:10:49,540 --> 00:10:51,265
bioinformatics,

218
00:10:51,265 --> 00:10:55,495
computer algebra, cryptography,
machine translation.

219
00:10:55,495 --> 00:10:58,975
Lots of things! If you come
a bit earlier in the years,

220
00:10:58,975 --> 00:11:00,970
algorithms and data structures,

221
00:11:00,970 --> 00:11:02,650
reasoning and agents,

222
00:11:02,650 --> 00:11:06,600
object-oriented programming,
software engineering.

223
00:11:06,600 --> 00:11:09,230
And if you come down to
the very early years,

224
00:11:09,230 --> 00:11:11,420
we find things like
computation and logic

225
00:11:11,420 --> 00:11:14,120
and functional programming,

226
00:11:14,120 --> 00:11:16,970
which are the subject
of this course.

227
00:11:16,970 --> 00:11:20,105
And they're here
in the first year

228
00:11:20,105 --> 00:11:23,060
because the things you will learn

229
00:11:23,060 --> 00:11:27,965
now will help you in all of
those different subjects.

230
00:11:27,965 --> 00:11:30,245
There are many subjects.

231
00:11:30,245 --> 00:11:32,390
It's impossible that any of

232
00:11:32,390 --> 00:11:35,045
you can take all of them
because there are too many.

233
00:11:35,045 --> 00:11:37,940
So that's another advantage
of talking to other people.

234
00:11:37,940 --> 00:11:39,680
Because if they're doing
something slightly

235
00:11:39,680 --> 00:11:41,570
different and you need a bit of

236
00:11:41,570 --> 00:11:43,700
knowledge about something
where you're not taking

237
00:11:43,700 --> 00:11:45,200
that deep course in

238
00:11:45,200 --> 00:11:46,400
that particular subject because

239
00:11:46,400 --> 00:11:48,395
you're developing
yourself elsewhere,

240
00:11:48,395 --> 00:11:50,750
you'll still find people
around who know about

241
00:11:50,750 --> 00:11:53,735
that stuff and can help
you if you need help.

242
00:11:53,735 --> 00:11:57,215
So we're going to do
something foundational.

243
00:11:57,215 --> 00:12:00,335
It's going to prepare you
for the rest of the course,

244
00:12:00,335 --> 00:12:02,360
the rest of your degree.

245
00:12:02,360 --> 00:12:04,760
And we have a motto for this course,

246
00:12:04,760 --> 00:12:06,905
which is Keep It Simple.

247
00:12:06,905 --> 00:12:11,345
The second S sometimes
is said Stupid,

248
00:12:11,345 --> 00:12:16,835
but it may just be Small
or it may be Satisfying.

249
00:12:16,835 --> 00:12:18,290
You can make your own second S,

250
00:12:18,290 --> 00:12:20,000
but keep it Simple.

251
00:12:20,000 --> 00:12:23,690
And in this course, we really will be

252
00:12:23,690 --> 00:12:28,070
exploring
small examples.

253
00:12:28,070 --> 00:12:31,550
But they nevertheless
are very interesting.

254
00:12:31,550 --> 00:12:35,329
And in fact, some of the
things that we're exploring,

255
00:12:35,329 --> 00:12:37,460
most of the things
we're exploring, are

256
00:12:37,460 --> 00:12:40,370
relatively recent inventions in

257
00:12:40,370 --> 00:12:41,600
the history of human thought.

258
00:12:41,600 --> 00:12:43,250
Even though some of
the problems that are

259
00:12:43,250 --> 00:12:46,415
addressing date
back to the Greeks.

260
00:12:46,415 --> 00:12:49,010
and before. You're
going to learn to use

261
00:12:49,010 --> 00:12:52,295
a general purpose programming
language, Haskell.

262
00:12:52,295 --> 00:12:55,310
It's very well adapted in
particular for this course,

263
00:12:55,310 --> 00:12:56,495
for a couple of reasons.

264
00:12:56,495 --> 00:12:58,370
A logic that allows us to reason

265
00:12:58,370 --> 00:13:01,070
about information,
propositional logic.

266
00:13:01,070 --> 00:13:04,625
And this is the simplest
logic you can think of.

267
00:13:04,625 --> 00:13:07,849
But it also turns out to
be remarkably complex

268
00:13:07,849 --> 00:13:11,359
in some strict computational sense.

269
00:13:11,359 --> 00:13:14,330
You'll learn about some
very simple machines

270
00:13:14,330 --> 00:13:15,410
that aren't as

271
00:13:15,410 --> 00:13:18,800
complicated as the machines

272
00:13:18,800 --> 00:13:20,990
that we like to
think we're using,

273
00:13:20,990 --> 00:13:24,170
but actually really are

274
00:13:24,170 --> 00:13:27,365
as complicated as any
machine we might build.

275
00:13:27,365 --> 00:13:28,820
So we like to think about

276
00:13:28,820 --> 00:13:32,074
some machines that might
have infinite memory,

277
00:13:32,074 --> 00:13:33,500
whereas we're going to study

278
00:13:33,500 --> 00:13:35,750
machines that don't
have infinite memory.

279
00:13:35,750 --> 00:13:37,670
Okay? We're going to find that

280
00:13:37,670 --> 00:13:42,570
even these simple systems
have quite complex behaviors.

281
00:13:43,500 --> 00:13:46,930
And we're going to talk about

282
00:13:46,930 --> 00:13:50,560
these systems in a
very abstract way.

283
00:13:50,560 --> 00:13:53,410
That is, we're not
building a machine

284
00:13:53,410 --> 00:13:55,090
when we talk about machines,

285
00:13:55,090 --> 00:13:57,610
we're building a
model of machine.

286
00:13:57,610 --> 00:14:02,350
And the way we get the simplicity
is by forgetting about

287
00:14:02,350 --> 00:14:04,780
many of the physical
aspects that make

288
00:14:04,780 --> 00:14:07,525
it difficult to build
a real computer.

289
00:14:07,525 --> 00:14:10,900
And think about an
idealized computer that

290
00:14:10,900 --> 00:14:14,410
we can study with
paper and pencil.

291
00:14:14,410 --> 00:14:16,420
We'll then find
things get a bit too

292
00:14:16,420 --> 00:14:18,580
complicated sometimes
for paper and pencil,

293
00:14:18,580 --> 00:14:20,860
so we'll also use Haskell as

294
00:14:20,860 --> 00:14:23,875
a tool to help us
study the logic.

295
00:14:23,875 --> 00:14:28,430
So we get this very introverted
recursive nature of

296
00:14:28,430 --> 00:14:29,960
the subject that we use

297
00:14:29,960 --> 00:14:33,920
the computers to help us
understand computers.

298
00:14:33,920 --> 00:14:39,785
Okay. That's all I wanted to
say to you in this video.

299
00:14:39,785 --> 00:14:42,320
And the next ones will include

300
00:14:42,320 --> 00:14:44,270
some technical material that

301
00:14:44,270 --> 00:14:45,800
I hope you'll find
more interesting,

302
00:14:45,800 --> 00:14:48,050
but don't forget to look

303
00:14:48,050 --> 00:14:50,855
after each other,
respect each other.

304
00:14:50,855 --> 00:14:54,755
Don't forget to talk
about your work.

305
00:14:54,755 --> 00:14:58,130
And don't forget when
you submit assessed work,

306
00:14:58,130 --> 00:15:00,960
make sure it's your own. 
Thank you!

